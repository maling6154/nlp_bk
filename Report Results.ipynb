{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, Flatten, Convolution2D, Convolution1D, Reshape, Lambda, AveragePooling1D, AveragePooling2D, MaxPooling1D\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.regularizers import l1, l2, l1\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import Merge\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2017-02-17  \n",
    "Feng Mai  \n",
    "\n",
    "Given the best selected models report results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_train_split_year = 2011\n",
    "\n",
    "\n",
    "\n",
    "def n_year_before(df, n = 1):\n",
    "    \"\"\"input x,y df, return df with y and n year before x\"\"\"\n",
    "    dat_tmp = df.copy()\n",
    "    dat_tmp['fyear'] = dat_tmp['fyear'] + n\n",
    "    dat_tmp = dat_tmp.drop('Y',axis =1)\n",
    "    Ys = df[['fyear','gvkey','Y']]\n",
    "    n_year = pd.merge(dat_tmp,Ys,how = 'inner',on=['fyear','gvkey'])\n",
    "    return n_year\n",
    "\n",
    "\n",
    "def load_data(X_padded_text, forecast_year = 1, random_split = False, random_state = 1001,\n",
    "              test_train_split_year = None):\n",
    "    \"\"\" Load tokenized word sequence and pad it for deep learning\n",
    "    If random_split, then treat it as a classification problem\n",
    "    If random_split is false, use test_train_split_year to split the dataset into training and spliting\n",
    "    \"\"\"   \n",
    "    index_10k = pd.read_csv('/shared/data/10k_2017/processed_corpus/10k_index.csv',usecols=['gvkey','fyear'])\n",
    "    index_10k['index_10k'] = index_10k.index\n",
    "    final_variable = pd.read_csv('data/final_variables.csv')\n",
    "    final_variable = final_variable.drop('Unnamed: 0',1)\n",
    "    final_variable = final_variable.replace([np.inf,-np.inf],0)\n",
    "\n",
    "    final_variable = final_variable.query('fyear <= 2014 & fyear >= 1993')\n",
    "    # match text index with one year after y, index_10k_y has the index of text data has one year after Y matched\n",
    "    index_10k_y = pd.merge(left=index_10k, right=final_variable, how='inner', on=['gvkey','fyear'])\n",
    "    print(\"Total number of observations with no forecasting: \")\n",
    "    print(index_10k_y.shape)\n",
    "    \n",
    "    index_10k_y_n_year = n_year_before(index_10k_y, n = forecast_year)\n",
    "    print(\"Total number of observations: \")\n",
    "    print(index_10k_y_n_year.shape)\n",
    "    # split train-test by year\n",
    "    index_10k_y_n_year = index_10k_y_n_year.sort_values(['gvkey', 'fyear'], ascending=[1, 1])\n",
    "    index_10k_y_n_year = index_10k_y_n_year.reset_index(drop=True)\n",
    "\n",
    "    if random_split:\n",
    "        all_index = index_10k_y_n_year.index.tolist()\n",
    "        split = sklearn.model_selection.train_test_split(all_index, train_size = 0.8, random_state=random_state)\n",
    "        pickle.dump(split, file=open(\"data/split.pickle_\" + str(forecast_year) + \"r\" + str(random_state), \"wb\"))\n",
    "        train_index = split[0]\n",
    "        test_index = split[1]\n",
    "    else:\n",
    "        train_index = index_10k_y_n_year[index_10k_y_n_year['fyear'] < test_train_split_year].index.tolist()\n",
    "        test_index = index_10k_y_n_year[index_10k_y_n_year['fyear'] >= test_train_split_year].index.tolist()\n",
    "    \n",
    "    y = np.array(index_10k_y_n_year['Y'])\n",
    "    X_text = X_padded_text[index_10k_y_n_year['index_10k'].tolist()] # get all text X which has matched one year after Y\n",
    "    X_num = index_10k_y_n_year.drop(['gvkey', 'fyear', 'datadate', 'cusip', 'PERMCO', 'Y', 'PERMNO', 'index_10k'], 1)\n",
    "    X_num = X_num.as_matrix()\n",
    "    print(len(train_index), len(test_index))\n",
    "    return X_text, X_num, train_index, test_index, y\n",
    "\n",
    "\n",
    "\n",
    "def performance_measure(pred_yp, x, y):\n",
    "    '''\n",
    "    Given lists of predicted y probability and x, y, return a dataframe of AR, AUC, Brier, Decile Table\n",
    "    '''\n",
    "    fpr,tpr,thresholds = roc_curve(y, pred_yp)\n",
    "    roc_auc = roc_auc_score(y, pred_yp)\n",
    "    accuracy_ratio = (roc_auc-0.5)*2\n",
    "    brier = metrics.brier_score_loss(y, pred_yp)\n",
    "    \n",
    "    tenc_dat = pd.DataFrame({'y_true':y,'probability':pred_yp.flatten()})\n",
    "    tenc_dat.sort_values('probability',axis = 0,ascending=False, inplace = True)\n",
    "    tenc_dat.index = range(0,len(tenc_dat))\n",
    "    y = tenc_dat['y_true']\n",
    "    point = float(len(tenc_dat))/10\n",
    "    point = int(round(point))\n",
    "    tenc = []\n",
    "    for i in range(0,10):\n",
    "        tenc.append(y[(i*point):((i+1)*point)])\n",
    "    tenc[9]=tenc[9].append(y[10*point:])\n",
    "    total = sum(y)\n",
    "    num_of_bkr = []\n",
    "    for j in range(0,10):\n",
    "        num_of_bkr.append(sum(tenc[j]))\n",
    "    tencile_bkr = np.array(num_of_bkr)\n",
    "    rate = tencile_bkr.astype(float)/total\n",
    "    tencile_result=pd.DataFrame({'Group':range(1,11),'Rate':rate})\n",
    "    # combine tencile 6 - 10\n",
    "    sum_6_to_10 = sum(tencile_result.loc[tencile_result['Group'] > 5]['Rate'])\n",
    "    tencile_result = tencile_result.loc[tencile_result['Group'] <= 5]\n",
    "    tencile_result = tencile_result.append({'Group':'6-10', 'Rate': sum_6_to_10}, ignore_index=True)\n",
    "    \n",
    "#     overall_results = pd.DataFrame({'Group':['Accuracy_ratio', 'AUC', 'Brier'],'Rate':[accuracy_ratio, roc_auc, brier]})\n",
    "    overall_results = pd.DataFrame({'Group':['Accuracy_ratio', 'AUC'],'Rate':[accuracy_ratio, roc_auc]})\n",
    "\n",
    "    return pd.concat([overall_results, tencile_result])\n",
    "\n",
    "\n",
    "def score_tencile_table_keras(model,x,y):\n",
    "    '''\n",
    "    input: a model and  X y\n",
    "    output: [ AUC, Accuracy Ratio, and Brier Score], a tencile table \n",
    "    '''\n",
    "    pred_yp = model.predict(x)\n",
    "    \n",
    "    return performance_measure(pred_yp, x, y)\n",
    "\n",
    "\n",
    "def compare_multiple_models_keras(model_list, x, y):\n",
    "    '''\n",
    "    Rowbind results for a list of models\n",
    "    '''\n",
    "    result_list = [score_tencile_table_keras(model,x,y) for model in model_list]\n",
    "    results = pd.concat(result_list, axis=1).drop(['Group'], axis=1)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_padded = pickle.load(open(\"data/10k/X_padded.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras results for textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-year ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_text, X_num, train_index, test_index, y = load_data(X_padded_text = X_padded, forecast_year = 1, random_split=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of observations with no forecasting: \n",
      "(95987, 44)\n",
      "Total number of observations: \n",
      "(83746, 44)\n",
      "66996 16750\n"
     ]
    }
   ],
   "source": [
    "X_text, X_num, train_index, test_index, y = load_data(X_padded_text = X_padded, \n",
    "                                                          forecast_year = 1, \n",
    "                                                          random_split=True, random_state = 1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.567878</td>\n",
       "      <td>0.427811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.783939</td>\n",
       "      <td>0.713906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.202381</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.154762</td>\n",
       "      <td>0.119048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rate      Rate\n",
       "0  0.567878  0.427811\n",
       "1  0.783939  0.713906\n",
       "0  0.357143  0.250000\n",
       "1  0.202381  0.190476\n",
       "2  0.154762  0.119048\n",
       "3  0.107143  0.178571\n",
       "4  0.059524  0.071429\n",
       "5  0.119048  0.190476"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_multiple_models_keras([load_model('model/final/y1/1004/text_embedding_1004_1y.mod2017-06-09 15:51:15'), \n",
    "                         load_model('model/final/y1/1004/text_cnn_1004_1y.mod2017-06-13 13:47:36')], X_text[test_index], y[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras results for numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of observations with no forecasting: \n",
      "(95987, 44)\n",
      "Total number of observations: \n",
      "(83746, 44)\n",
      "66996 16750\n"
     ]
    }
   ],
   "source": [
    "X_text, X_num, train_index, test_index, y = load_data(X_padded_text = X_padded, forecast_year = 1, random_split = True, random_state = 1004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633211</td>\n",
       "      <td>0.603058</td>\n",
       "      <td>0.596655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816606</td>\n",
       "      <td>0.801529</td>\n",
       "      <td>0.798328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.345238</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>0.321429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.119048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rate      Rate      Rate\n",
       "0  0.633211  0.603058  0.596655\n",
       "1  0.816606  0.801529  0.798328\n",
       "0  0.404762  0.345238  0.238095\n",
       "1  0.250000  0.202381  0.321429\n",
       "2  0.142857  0.238095  0.238095\n",
       "3  0.119048  0.095238  0.119048\n",
       "4  0.035714  0.083333  0.035714\n",
       "5  0.047619  0.035714  0.047619"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_multiple_models_keras([load_model('model/final/y1/1004/num_simple_1004_1y.mod2017-06-09 17:57:28'), \n",
    "                         load_model('model/final/y1/1004/num_deeper_1004_1y.mod2017-06-09 17:59:13'),\n",
    "                         load_model('model/final/y1/1004/num_wider_1004_1y.mod2017-06-09 18:11:02')], X_num[test_index], y[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all numerical data\n",
    "final_variable = pd.read_csv('data/final_variables.csv')\n",
    "final_variable = final_variable.drop('Unnamed: 0',1)\n",
    "drop_list = ['gvkey','datadate','fyear','cusip','PERMNO','PERMCO', 'Y']\n",
    "all_x_var = list(final_variable.drop(drop_list, axis=1))\n",
    "print(all_x_var)\n",
    "\n",
    "test_train_split_year = 2011\n",
    "forecast_year = 1\n",
    "\n",
    "def n_year_before(df, n = 1):\n",
    "    \"\"\"input x,y df, return df with y and n year before x\"\"\"\n",
    "    dat_tmp = df.copy()\n",
    "    dat_tmp['fyear'] = dat_tmp['fyear'] + n\n",
    "    dat_tmp = dat_tmp.drop('Y',axis =1)\n",
    "    Ys = df[['fyear','gvkey','Y']]\n",
    "    n_year = pd.merge(dat_tmp,Ys,how = 'inner',on=['fyear','gvkey'])\n",
    "    return n_year\n",
    "\n",
    "def load_aligned_data(how='text', svd=False, forecast_year = 1, test_train_split_year = None, random_state = None):\n",
    "    [train_x, train_y, test_x, test_y] = [None, None, None, None]\n",
    "    suffix = \"r\" + str(random_state)\n",
    "    if test_train_split_year is not None:\n",
    "        suffix = \"_\" + str(test_train_split_year)\n",
    "    if how == \"text\":\n",
    "        if svd is True:\n",
    "            [train_x, train_y, test_x, test_y] = pickle.load(open(\"data/aligned/sklearn_textsvd_\" + str(forecast_year)+suffix, 'rb'))\n",
    "        else:\n",
    "            [train_x, train_y, test_x, test_y] = pickle.load(open(\"data/aligned/sklearn_text_\" + str(forecast_year)+suffix, 'rb'))\n",
    "    if how == \"num\":\n",
    "        [train_x, train_y, test_x, test_y] = pickle.load(open(\"data/aligned/sklearn_num_\"+ str(forecast_year) + suffix, 'rb'))\n",
    "    if how == \"total\":\n",
    "        if svd is True:\n",
    "            [train_x, train_y, test_x, test_y] = pickle.load(open(\"data/aligned/sklearn_totalsvd_\" + str(forecast_year) + suffix, 'rb'))\n",
    "        else:\n",
    "            [train_x, train_y, test_x, test_y] = pickle.load(open(\"data/aligned/sklearn_total_\" + str(forecast_year) + suffix, 'rb'))\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "def tencile_table_sklearn(model,x,y):\n",
    "    '''\n",
    "    input: a model and  X y\n",
    "    output: a tencile table\n",
    "    '''\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        pred_yp = model.predict_proba(x)[:,1]\n",
    "    else:\n",
    "        from sklearn.calibration import CalibratedClassifierCV\n",
    "        clf = CalibratedClassifierCV(model) \n",
    "        clf.fit(train_x, train_y)\n",
    "        pred_yp = clf.predict_proba(test_x)[:,1]\n",
    "    \n",
    "    return performance_measure(pred_yp, x, y)\n",
    "\n",
    "\n",
    "def f1_sklearn(model,x,y, class_ratio = 20):\n",
    "    '''\n",
    "    UNFINISHED\n",
    "    input: a model and  X y\n",
    "    output: a tencile table\n",
    "    '''\n",
    "    pred_yp = model.predict_proba(x)[:,1]\n",
    "    return performance_measure(pred_yp, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn results for textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-year ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = load_aligned_data(how=\"text\", svd=None, test_train_split_year= None, random_state = 1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"model/final/y1/1004/text_lg.pickle\", 'rb'))\n",
    "results.append(tencile_table_sklearn(model, test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"model/final/y1/1004/text_SVM-text.pickle\", 'rb'))\n",
    "results.append(tencile_table_sklearn(model, test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"model/final/y1/1004/text_random_forest.pickle\", 'rb'))\n",
    "results.append(tencile_table_sklearn(model, test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(results, axis=1).drop(['Group'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn results for numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-year ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = load_aligned_data(how= \"num\", svd=None, test_train_split_year= None, random_state = 1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"model/final/y1/1004/num_lg.pickle\", 'rb'))\n",
    "results.append(tencile_table_sklearn(model, test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"model/final/y1/1004/num_SVM-num.pickle\", 'rb'))\n",
    "results.append(tencile_table_sklearn(model, test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"model/final/y1/1004/num_random_forest-num.pickle\", 'rb'))\n",
    "results.append(tencile_table_sklearn(model, test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(results, axis=1).drop(['Group'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
